---
title: "Les p-values : comment les comprendre et les interpréter"
author: "Antoine"
date: "??/??/????"
output: 
  html_document:
    toc: true
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

[TOC]\  

Aujourd'hui c'est à un grand classique de la statistique que l'on s'attaque : la __p-value, ou p valeur__. Fondamentale dans l'interprétation des résultats de la littérature scientifique, elle est pourtant __souvent mal interprétée__. C'est sur elle que l'on s'appuie pour __confirmer ou infirmer une hypothèse__ et juger de la __significativé de nos résultats__. Mais qu'est-ce que cela implique et comment bien appréhender ce qu'elle permet (et surtout ce qu'elle ne permet pas) de conclure? On essaye de voir ça ensemble, de la manière la plus intuitive possible!  

# Les p-values et les tests statistiques  

Pour comprendre les p-values, il faut aborder la notion de __tests statistiques__. Ces tests permettent de tester une __Hypothèse nulle `H0`__ contre une __hypothèses alternative `H1`__. Par exemple, dans le cas d'une régression linéaire, on utilise le test t de student qui nous permet de tester pour chaque coefficient   \(\beta_i\) :  
- `H0` : \(\beta_i  = 0\)  

Le principe du test est le suivant : on va __partir du principe que H0 est vrai__ et on va voir si __le résultat que l'on obtient est vraisemblable__ dans ce monde théorique. Ce test statistique va ainsi nous donner la __distribution possible des résultats que l'on pourrait obtenir si `H0` était vraie__. Selon où l'on se situe dans cette distribution, on va pouvoir juger de la __vraisemblance de cette hypothèse H0__, en fonction d'un __seuil alpha que l'on peut faire varier__. En fonction de la valeur de t obtenue dans notre échantillon, on peut juger de la vraisemblance de l'hypothèse `H0` :  

```{r echo=FALSE}
# Chargement des bibliothèques nécessaires
library(ggplot2)

# Définition des paramètres
df <- 30  # degrés de liberté
alpha <- 0.05  # niveau de signification

# Calcul des valeurs critiques pour les intervalles de confiance à 95%
t_critique_gauche <- qt(alpha / 2, df)  # Valeur critique gauche
t_critique_droite <- qt(1 - alpha / 2, df)  # Valeur critique droite

# Création d'une séquence de valeurs t
t_values <- seq(-4, 4, length.out = 1000)  # Séquence de valeurs t

# Calcul de la densité de la distribution t
density_values <- dt(t_values, df)  # Densité de la distribution t

# Création du dataframe pour ggplot
df_plot <- data.frame(t_values = t_values, density_values = density_values)

# Création du graphique
ggplot(df_plot, aes(x = t_values, y = density_values)) +
  geom_line(color = "blue") +
  geom_area(data = subset(df_plot, t_values < t_critique_gauche), 
            aes(x = t_values, y = density_values), fill = "red", alpha = 0.5) +
  geom_area(data = subset(df_plot, t_values > t_critique_droite), 
            aes(x = t_values, y = density_values), fill = "red", alpha = 0.5) +
  geom_vline(xintercept = c(t_critique_gauche, t_critique_droite), linetype = "dashed", color = "black") +
  labs(title = "Distribution du t de Student",
       x = "Valeurs de t",
       y = "Densité",
       subtitle = "Région de p-value à 5% (en rouge)") +
  theme_bw()
```

Sur le graphique ci-dessus par exemple, si la valeur obtenue est dans la zone rouge on sait que __cela représenterait 5% ou moins des résultats possibles que l'on aurait obtenus si `H0` était vraie__. On juge donc que __la nullité du coefficient est peu vraisemblable__. Graphiquement, la zone rouge représente __5% de l'aire de la courbe__. 

Bien sûr, si on modifie le seuil alpha dans un sens plus restrictif, en jugeant par exemple qu'on ne considérera un coefficient significatif seulement s'il l'est à 1%, cela va restreindre la zone rouge de notre graphique. Il faudra alors obtenir __une valeur `t` plus extrême pour rejeter `H0`__ : 

```{r echo=FALSE}
# Chargement des bibliothèques nécessaires
library(ggplot2)

# Définition des paramètres
df <- 30  # degrés de liberté
alpha <- 0.01  # niveau de signification

# Calcul des valeurs critiques pour les intervalles de confiance à 95%
t_critique_gauche <- qt(alpha / 2, df)  # Valeur critique gauche
t_critique_droite <- qt(1 - alpha / 2, df)  # Valeur critique droite

# Création d'une séquence de valeurs t
t_values <- seq(-4, 4, length.out = 1000)  # Séquence de valeurs t

# Calcul de la densité de la distribution t
density_values <- dt(t_values, df)  # Densité de la distribution t

# Création du dataframe pour ggplot
df_plot <- data.frame(t_values = t_values, density_values = density_values)

# Création du graphique
ggplot(df_plot, aes(x = t_values, y = density_values)) +
  geom_line(color = "blue") +
  geom_area(data = subset(df_plot, t_values < t_critique_gauche), 
            aes(x = t_values, y = density_values), fill = "red", alpha = 0.5) +
  geom_area(data = subset(df_plot, t_values > t_critique_droite), 
            aes(x = t_values, y = density_values), fill = "red", alpha = 0.5) +
  geom_vline(xintercept = c(t_critique_gauche, t_critique_droite), linetype = "dashed", color = "black") +
  labs(title = "Distribution du t de Student",
       x = "Valeurs de t",
       y = "Densité",
       subtitle = "Région de p-value à 1% (en rouge)") +
  theme_bw()
```

Ainsi, lorsqu'on fait tourner un modèle de régression sur notre logiciel de statistiques favori et que l'on obtient une p-value, il s'agit du __seuil de vraisemblance maximum de notre hypothèse `H0`__. On va donc l'interpréter comme __la vraisemblance que notre coefficient soit égal zéro__, ou encore comme la __significativité de ce coefficient__. Si l'on devait synthétiser ce que veut dire la p-value en une phrase, cela pourrait être :  
> Si la vraie valeur du coefficient était 0 et que j'avais fait tourner ce modèle sur 100 échantillons différents, j'aurais obtenu un résultat au moins aussi extrême dans p cas.  

Ainsi, __plus p est faible, plus on peut écarter l'hypothèse que le coefficient estimé soit en fait nul__.  

# Interprétation des p-values

Il faut bien comprendre que la p-value et la __significativité du coefficient__ qui en découle ne porte que sur la question de savoir si ce coefficient est ou non différent de zéro. Cela n'indique pas si le résultat trouvé a une importance particulière. Un coefficient peut très bien être __significatif statistiquement__ (donc différent de zéro très probablement) mais __en pratique insignifiant__. Il faut donc le confronter à l'expertise pratique de la question de recherche étudiée.  
De plus, un résultat peut être non significatif en raison d'une mauvaise calibration du modèle : un échantillon trop peu important, de trop nombreuses variables explicatives, etc... C'est notamment pour cette raison qu'il __ne faut pas directement interpréter un coefficient non significatif comme un absence d'effet__. C'est plutôt une absence de preuve d'effet. Oui, c'est moins facile à rédiger, mais cela rend plus justice à la complexité des statistiques inférentielles.  
En général, le consensus scientifique fixe le __seuil de significativité à 5%__. Bien sûr, c'est forcément au moins partiellement arbitraire et cela pose question : on écarterait un résultat avec une p-value à 5,1% mais on afficherait fièrement celui avec une p-value à 4,9%?  
Il est ainsi tentant pour les chercheurs de construire leur modèle en fonction de la p-value recherchée, et non de la question de recherche affichée, ce qui est complètement contre-productif. D'autant que la nature de la p-value fait que __si l'on teste suffisamment de fois, on finira bien par trouver des résultats significatifs__, mais uniquement du fait du hasard. Cette mauvaise pratique est bien identifiée et se nomme le [p-hacking](https://en.wikipedia.org/wiki/Data_dredging). La bonne manière de se prémunir de cet écueil est de __définir la question de recherche et les modèles statistiques en amont de la collecte de données__ et de calibrer l'échantillon en fonction de ceux-ci. Il faut ensuite tâcher de ne pas s'écarter de ces axes de recherche...même si on n'obtient pas les p-values qu'on espérait!  

# Conclusion   

La p-value, ça n'est donc pas du tout la _probabilité que le coefficient soit incorrect_! Dans le cas d'une régression, c'est un indicateur de la vraisemblance que celui-ci soit égal à zéro. Mais __un coefficient significatif peut aussi avoir une estimation très imprécise, ou une valeur insignifiante__. Il est donc fondamental d'affiner son diagnostic, avec par exemple les intervalles de confiance, et surtout l'interprétation de quelqu'un qui comprend les implications pratiques d'un coefficient!  

C'est tout pour aujourd'hui! N'hésitez pas à [visiter notre site (qui a fait peau neuve, vous avez remarqué?)](https://www.statoscop.fr) et à nous suivre sur [Twitter](https://twitter.com/stato_scop) et [Linkedin](https://www.linkedin.com/company/statoscop). Pour retrouver le code ayant servi à générer cette note, vous pouvez vous rendre sur le [github de Statoscop](https://github.com/Statoscop/notebooks-blog).  
